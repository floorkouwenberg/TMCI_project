{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning with plmi weighting and co-occs\n",
    "\n",
    "This notebook will apply Naive Bayes on the co-occurences with plmi-weighting of our training set. First the PLMI score will be used instead of the frequency count. After this the PLMI score will be multiplied by the frequency count to see if this has any effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import naive_bayes, metrics\n",
    "from itertools import chain\n",
    "from math import log\n",
    "from nltk import BigramAssocMeasures\n",
    "\n",
    "#Importing the test and train sets\n",
    "with open('test_dicts.txt', 'rb') as file:\n",
    "    test_lemmedreviews = pickle.load(file)\n",
    "    \n",
    "with open('training_dicts.txt', 'rb') as file:\n",
    "    train_lemmedreviews = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the co-occurences\n",
    "span = 3\n",
    "cooccs_candidate_feature = Counter()\n",
    "\n",
    "for p in range(1, 6):\n",
    "    for sentence in train_lemmedreviews[p]:\n",
    "        for i,w in enumerate(sentence):\n",
    "            #check all co-occurring words within a 3 word span \n",
    "            span_range = list(range(max(i- span, 0), i)) \n",
    "            span_range.extend(range(i+1, min(i + span + 1, len(sentence)))) \n",
    "            for cw in [sentence[idx] for idx in span_range]:\n",
    "                if cw != w and (cw, w) not in cooccs_candidate_feature:\n",
    "                    cooccs_candidate_feature[(w, cw)] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected features: 6845\n"
     ]
    }
   ],
   "source": [
    "#Selecting all features tha occur more than 9 times\n",
    "cooccs_features = dict()\n",
    "\n",
    "for idx, (f, v) in enumerate(cooccs_candidate_feature.most_common()):\n",
    "    if v == 9:\n",
    "    #    print(idx, f, v)\n",
    "        break\n",
    "\n",
    "    cooccs_features[f] = idx\n",
    "    \n",
    "print(\"selected features:\", len(cooccs_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(o_11, r_1, c_1, n):\n",
    "    \"\"\"\n",
    "    Positive Pointwise Mutual Information (Church & Hanks, 1990)\n",
    "    \n",
    "    PMI is also available in NLTK:\n",
    "    from nltk.metrics import BigramAssocMeasures\n",
    "    print BigramAssocMeasures.pmi(8, (15828, 4675), 14307668)\n",
    "    \"\"\"\n",
    "    observed = o_11\n",
    "    expected = (r_1*c_1)/n \n",
    "    if expected == 0:\n",
    "        res = 0\n",
    "    else: \n",
    "        if observed/expected <= 0: \n",
    "            res = 0 \n",
    "        else: \n",
    "            res = log(observed/expected,2)\n",
    "    return max(0, res)\n",
    "\n",
    "def plmi(o_11, r_1, c_1, n):\n",
    "    \"\"\"\n",
    "    Positive Local Mutual Information, useful for leveraging the \n",
    "    low-frequency bias of the PPMI\n",
    "    \"\"\"\n",
    "    res = o_11 * ppmi(o_11, r_1, c_1, n)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('costa-NOUN', 'rica-NOUN'), 163566.0021038179), (('navitas-NOUN', 'natural-NOUN'), 157660.78858215877), (('dulce-NOUN', 'de-NOUN'), 155685.75603858862), (('duncan-ADJ', 'hines-NOUN'), 145248.5840490909), (('buffalo-NOUN', 'bill-NOUN'), 144755.08555179246), (('organic-ADJ', 'mechanically-ADV'), 141409.26818245227), (('ascorbic-NOUN', 'acid-NOUN'), 138032.22368957847), (('rodeo-NOUN', 'blend-VERB'), 135047.17208362938), (('organic-ADJ', 'separate-VERB'), 133214.8290435124), (('web-NOUN', 'site-NOUN'), 132346.67722292893)]\n"
     ]
    }
   ],
   "source": [
    "#Creating the raw frequencies count for plmi\n",
    "raw_frequencies = Counter()\n",
    "for p in range(1, 6):\n",
    "    for rev in train_lemmedreviews[p]:\n",
    "        for w in rev:\n",
    "            raw_frequencies[w] += 1\n",
    "\n",
    "#Creating the plmi scores            \n",
    "plmis_lem_surface = Counter()\n",
    "N = len(cooccs_candidate_feature.values())\n",
    "\n",
    "for k,v in cooccs_features.items():\n",
    "    plmis_lem_surface[k] = plmi(v, raw_frequencies[k[0]], raw_frequencies[k[1]], N)\n",
    "\n",
    "print(plmis_lem_surface.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning with plmi weighting instead of frequencies with co-occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [1. 1. 1. ... 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "#Creating the matrix with co-occurence counts\n",
    "fMat = np.zeros((sum([len(v) for v in train_lemmedreviews.values()]), len(cooccs_features)))\n",
    "#Creating the labels\n",
    "labelsVec = np.zeros((sum([len(v) for v in train_lemmedreviews.values()])))\n",
    "\n",
    "docId = 0\n",
    "for score in range(1, 6):\n",
    "    for rev in train_lemmedreviews[score]:\n",
    "        labelsVec[docId] = score\n",
    "        span = 3\n",
    "        cooccs_rev = Counter()\n",
    "        \n",
    "        #Creating the co-occurences per review\n",
    "        for i,w in enumerate(rev):\n",
    "            #check all co-occurring words within a 3 word span \n",
    "            span_range = list(range(max(i- span, 0), i)) \n",
    "            span_range.extend(range(i+1, min(i + span + 1, len(rev)))) \n",
    "            for cw in [rev[idx] for idx in span_range]:\n",
    "                if cw != w and (cw, w) not in cooccs_rev:\n",
    "                    cooccs_rev[(w, cw)] += 1\n",
    "        \n",
    "        #Using the plmi weight\n",
    "        for cooccs in list(cooccs_rev.keys()):\n",
    "            if cooccs in cooccs_features:\n",
    "                fMat[docId, cooccs_features[cooccs]] = plmis_lem_surface[cooccs]\n",
    "\n",
    "        docId += 1\n",
    "        \n",
    "print(fMat, labelsVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a model\n",
    "clf = naive_bayes.MultinomialNB()\n",
    "clf.fit(fMat, labelsVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [1. 1. 1. ... 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "#Creating the matrix with co-occurence counts\n",
    "testMat = np.zeros((sum([len(v) for v in test_lemmedreviews.values()]), len(cooccs_features)))\n",
    "#Creating the goldStandard\n",
    "goldStandard = np.zeros((sum([len(v) for v in test_lemmedreviews.values()])))\n",
    "\n",
    "docId = 0\n",
    "for score in range(1, 6):\n",
    "    for rev in test_lemmedreviews[score]:\n",
    "        goldStandard[docId] = score        \n",
    "        span = 3\n",
    "        cooccs_rev = Counter()\n",
    "\n",
    "        #Creating the co-occurences\n",
    "        for i,w in enumerate(rev):\n",
    "            #check all co-occurring words within a 3 word span \n",
    "            span_range = list(range(max(i- span, 0), i)) \n",
    "            span_range.extend(range(i+1, min(i + span + 1, len(rev)))) \n",
    "            for cw in [rev[idx] for idx in span_range]:\n",
    "                if cw != w and (cw, w) not in cooccs_rev:\n",
    "                    cooccs_rev[(w, cw)] += 1\n",
    "        \n",
    "        #Using the PLMI weighting\n",
    "        for cooccs in list(cooccs_rev.keys()):\n",
    "            if cooccs in cooccs_features:\n",
    "                testMat[docId, cooccs_features[cooccs]] = plmis_lem_surface[cooccs]\n",
    "\n",
    "        docId += 1\n",
    "        \n",
    "print(testMat, goldStandard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the prediction\n",
    "predicted = clf.predict(testMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.716\n",
      "precision: 0.7242050504553431\n",
      "recall: 0.6138217156949433\n",
      "f1-measure: 0.6554062336967708\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(predicted, goldStandard))\n",
    "\n",
    "# precision, recall and f-measure\n",
    "print(\"precision:\", metrics.precision_score(predicted, goldStandard, average='macro'))\n",
    "print(\"recall:\", metrics.recall_score(predicted, goldStandard, average='macro'))\n",
    "print(\"f1-measure:\", metrics.f1_score(predicted, goldStandard, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning with plmi weighting times frequencies with co-occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [1. 1. 1. ... 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "#Creating the matrix with features per review\n",
    "fMat = np.zeros((sum([len(v) for v in train_lemmedreviews.values()]), len(cooccs_features)))\n",
    "#Creating the labels\n",
    "labelsVec = np.zeros((sum([len(v) for v in train_lemmedreviews.values()])))\n",
    "\n",
    "docId = 0\n",
    "for score in range(1, 6):\n",
    "    for rev in train_lemmedreviews[score]:\n",
    "        labelsVec[docId] = score\n",
    "        span = 3\n",
    "        cooccs_rev = Counter()\n",
    "        \n",
    "        #Creating the co-occurences per review\n",
    "        for i,w in enumerate(rev):\n",
    "            #check all co-occurring words within a 3 word span \n",
    "            span_range = list(range(max(i- span, 0), i)) \n",
    "            span_range.extend(range(i+1, min(i + span + 1, len(rev)))) \n",
    "            for cw in [rev[idx] for idx in span_range]:\n",
    "                if cw != w and (cw, w) not in cooccs_rev:\n",
    "                    cooccs_rev[(w, cw)] += 1\n",
    "        \n",
    "        #Use frequency times PLMI as weighting\n",
    "        for cooccs in list(cooccs_rev.keys()):\n",
    "            if cooccs in cooccs_features:\n",
    "                fMat[docId, cooccs_features[cooccs]] = plmis_lem_surface[cooccs]*cooccs_rev[cooccs]\n",
    "\n",
    "        docId += 1\n",
    "        \n",
    "print(fMat, labelsVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a model\n",
    "clf = naive_bayes.MultinomialNB()\n",
    "clf.fit(fMat, labelsVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [1. 1. 1. ... 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "#Creating the matrix with features per review\n",
    "testMat = np.zeros((sum([len(v) for v in test_lemmedreviews.values()]), len(cooccs_features)))\n",
    "#Creating the golden standard\n",
    "goldStandard = np.zeros((sum([len(v) for v in test_lemmedreviews.values()])))\n",
    "\n",
    "docId = 0\n",
    "for score in range(1, 6):\n",
    "    for rev in test_lemmedreviews[score]:\n",
    "        goldStandard[docId] = score\n",
    "        span = 3\n",
    "        cooccs_rev = Counter()\n",
    "        \n",
    "        #Creating the co-occurences per review\n",
    "        for i,w in enumerate(rev):\n",
    "            #check all co-occurring words within a 3 word span \n",
    "            span_range = list(range(max(i- span, 0), i)) \n",
    "            span_range.extend(range(i+1, min(i + span + 1, len(rev)))) \n",
    "            for cw in [rev[idx] for idx in span_range]:\n",
    "                if cw != w and (cw, w) not in cooccs_rev:\n",
    "                    cooccs_rev[(w, cw)] += 1\n",
    "        \n",
    "        #Creating the right weighting\n",
    "        for cooccs in list(cooccs_rev.keys()):\n",
    "            if cooccs in cooccs_features:\n",
    "                testMat[docId, cooccs_features[cooccs]] = plmis_lem_surface[cooccs]*cooccs_rev[cooccs]\n",
    "\n",
    "        docId += 1\n",
    "        \n",
    "print(testMat, goldStandard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a prediction\n",
    "predicted = clf.predict(testMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7235\n",
      "precision: 0.7276499933526859\n",
      "recall: 0.6217073670575455\n",
      "f1-measure: 0.6624970984160434\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(predicted, goldStandard))\n",
    "\n",
    "# precision, recall and f-measure\n",
    "print(\"precision:\", metrics.precision_score(predicted, goldStandard, average='macro'))\n",
    "print(\"recall:\", metrics.recall_score(predicted, goldStandard, average='macro'))\n",
    "print(\"f1-measure:\", metrics.f1_score(predicted, goldStandard, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
